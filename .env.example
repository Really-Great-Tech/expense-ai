# Production Environment Configuration
# This file contains production-optimized settings for AWS deployments
# Copy this to .env and update with your actual values

# =============================================================================
# ENVIRONMENT
# =============================================================================
NODE_ENV=production
PORT=3000

# =============================================================================
# AURORA MYSQL DATABASE CONFIGURATION (IAM Authentication - RECOMMENDED)
# =============================================================================
# Use Aurora cluster endpoints for high availability
# Writer endpoint: For read/write operations
# Reader endpoint: For read-only operations (optional, can implement read replicas later)

# Aurora Cluster Configuration
MYSQL_HOST=your-aurora-cluster.cluster-xxxxx.us-east-1.rds.amazonaws.com
MYSQL_PORT=3306
MYSQL_USER=iam_db_user
MYSQL_DATABASE=expense_ai

# SSL Configuration (automatically enabled with IAM auth)
# Required for Aurora in production
MYSQL_SSL=true

# IAM Database Authentication (RECOMMENDED for production)
# Eliminates hardcoded passwords, uses AWS IAM for authentication
# Prerequisites:
#   1. IAM authentication enabled on Aurora cluster
#   2. Database user created with: IDENTIFIED WITH AWSAuthenticationPlugin AS 'RDS'
#   3. IAM policy attached to ECS task role / EC2 instance role
#   4. Policy grants: rds-db:connect for cluster resource
MYSQL_IAM_AUTH_ENABLED=true

# Note: MYSQL_PASSWORD is NOT needed when IAM auth is enabled
# Tokens are generated automatically using AWS credentials from:
# - ECS Task Role (for ECS/Fargate)
# - EC2 Instance Role (for EC2)
# - IRSA (for EKS)

# Connection Pool Configuration (optimized for Aurora)
# Adjust based on your instance size and expected load
# Aurora db.r5.large supports ~1000 connections
# Keep pool size at 50-70% of max_connections per instance
DB_CONNECTION_LIMIT=50
DB_QUEUE_LIMIT=0

# =============================================================================
# TYPEORM CONFIGURATION (Production Safeguards)
# =============================================================================

# CRITICAL: NEVER enable synchronize in production
# This will automatically alter your schema and can cause DATA LOSS
TYPEORM_SYNCHRONIZE=false

# CRITICAL: NEVER auto-run migrations in production
# Migrations must be run manually via CLI for safety and control
# Use: npm run migration:run (after testing in staging)
TYPEORM_MIGRATIONS_RUN=false

# Logging Configuration
# Options: 'all' (logs every query, use only for debugging), '' (errors and warnings only)
# Production recommendation: Leave empty or set to 'error'
TYPEORM_LOGGING=

# =============================================================================
# AWS CONFIGURATION
# =============================================================================

# AWS Region (must match your Aurora cluster region)
AWS_REGION=us-east-1

# AWS Credentials
# ⚠️ IMPORTANT: For production, use IAM roles instead of access keys
# - ECS/Fargate: Attach IAM role to ECS task definition (taskRoleArn)
# - EC2: Attach IAM role to EC2 instance
# - EKS: Use IRSA (IAM Roles for Service Accounts)
# Only set these for local testing or if IAM roles are not available:
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# =============================================================================
# REDIS CONFIGURATION (AWS ElastiCache)
# =============================================================================

# Redis Mode: MUST be 'managed' for production
REDIS_MODE=managed

# -----------------------------------------------------------------------------
# ElastiCache Configuration (Cluster Mode Disabled - RECOMMENDED)
# -----------------------------------------------------------------------------
# Use this configuration for most production workloads
# Supports: single-node, replication groups (1 primary + up to 5 replicas)
# Provides: automatic failover, read scaling, simplified management

# Cluster Mode Setting
REDIS_CLUSTER_ENABLED=false

# ElastiCache Endpoint
# For replication groups: Use the primary endpoint
# Format: your-cluster.xxxxx.cache.amazonaws.com
REDIS_HOST=your-production-cluster.xxxxx.use1.cache.amazonaws.com
REDIS_PORT=6379

# Authentication
# Recommendation: Store in AWS Secrets Manager
# Retrieve with: aws secretsmanager get-secret-value --secret-id prod/redis/auth-token
REDIS_PASSWORD=your_auth_token_from_secrets_manager

# Username (Optional - Only if ElastiCache ACL is enabled)
# If your ElastiCache cluster uses ACLs (Redis 6.0+), uncomment and set:
# REDIS_USERNAME=app-user
#
# If ACL is NOT enabled (most common), leave this commented out
# The application will work without username for non-ACL clusters

# TLS Configuration (Encryption in-transit - REQUIRED for production)
REDIS_TLS_ENABLED=true

# TLS Servername (CRITICAL: Must match endpoint exactly)
# This prevents SNI mismatch errors during TLS handshake
# Default: Uses REDIS_HOST value if not specified
REDIS_TLS_SERVERNAME=your-production-cluster.xxxxx.use1.cache.amazonaws.com

# TLS Certificate Validation
# Set to true for production (validates AWS certificate)
REDIS_TLS_REJECT_UNAUTHORIZED=true

# Connection Configuration
REDIS_LAZY_CONNECT=true              # Delays connection until first command (graceful startup)
REDIS_KEEP_ALIVE_MS=60000            # TCP keepalive interval (prevents idle timeout)
REDIS_CONNECTION_TIMEOUT_MS=10000    # Initial connection timeout (10 seconds)
REDIS_COMMAND_TIMEOUT_MS=5000        # Individual command timeout (5 seconds)
REDIS_MAX_RETRIES_PER_REQUEST=3      # Max retries per command before failing

# Retry Strategy (Exponential backoff for connection failures)
REDIS_RETRY_BASE_DELAY_MS=1000       # Initial retry delay (1 second)
REDIS_RETRY_MAX_DELAY_MS=30000       # Maximum retry delay (30 seconds)
REDIS_MAX_TOTAL_RETRIES=10           # Max connection retry attempts before giving up

# Performance Optimization
REDIS_ENABLE_READY_CHECK=false       # Disable for faster connections (recommended for ElastiCache)



# =============================================================================
# FILE STORAGE (AWS S3 - RECOMMENDED for production)
# =============================================================================

# Storage Type
STORAGE_TYPE=local

# S3 Bucket Configuration
S3_BUCKET_NAME=expenses-ai-production
# S3 credentials inherited from AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
# Or use IAM role (recommended)

# File Upload Limits
MAX_FILE_SIZE=50MB
UPLOAD_PATH=/app/uploads  # Local temp storage before S3 upload

# =============================================================================
# DOCUMENT PROCESSING (AWS Textract)
# =============================================================================

# Document Reader
DOCUMENT_READER=textract

# =============================================================================
# LLM CONFIGURATION (AWS Bedrock)
# =============================================================================

# Bedrock Judge Models (for validation)
# Use diverse models for better consensus
BEDROCK_JUDGE_MODEL_1=us.anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_JUDGE_MODEL_2=us.anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_JUDGE_MODEL_3=us.anthropic.claude-3-5-sonnet-20241022-v2:0

# Primary Bedrock Model
BEDROCK_MODEL=us.amazon.nova-pro-v1:0

# Citation Model (lightweight for citations)
CITATION_MODEL=us.amazon.nova-micro-v1:0

# Langfuse S3 Media Upload
LANGFUSE_S3_MEDIA_UPLOAD_BUCKET=expenses-ai-langfuse-production

# =============================================================================
# JOB QUEUE CONFIGURATION
# =============================================================================

# Queue Concurrency (adjust based on instance size and workload)
QUEUE_CONCURRENCY=20
MAX_RETRY_ATTEMPTS=3
JOB_TIMEOUT=300000

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Splitter Configuration
SPLITTER_CONFIDENCE_THRESHOLD=0.75
SPLITTER_MAX_INVOICES=10

# API Documentation (Swagger)
# Recommendation: Disable in production or protect with authentication
ENABLE_SWAGGER=true

# Rate Limiting (enabled for production)
ENABLE_THROTTLING=true
THROTTLE_TTL=60
THROTTLE_LIMIT=100

# =============================================================================
# SECURITY - JWT KEYS
# =============================================================================

# JWT Keys for authentication
# ⚠️ CRITICAL: Store these in AWS Secrets Manager
# Generate with: ssh-keygen -t rsa -b 4096 -m PEM
# Then: aws secretsmanager create-secret --name expense-ai/jwt/private-key --secret-string "$(cat private.pem)"
#
# For production, inject from Secrets Manager at runtime:
# AWS CLI: aws secretsmanager get-secret-value --secret-id expense-ai/jwt/private-key --query SecretString --output text
# ECS: Use secretOptions in task definition
# EKS: Use External Secrets Operator

PRIVATE_KEY="-----BEGIN RSA PRIVATE KEY-----\nMIIJKAIBAAKCAgEA...(your_actual_private_key)...\n-----END RSA PRIVATE KEY-----\n"
PUBLIC_KEY="-----BEGIN PUBLIC KEY-----\nMIICIjANBgkqhkiG...(your_actual_public_key)...\n-----END PUBLIC KEY-----\n"

# =============================================================================
# OBSERVABILITY
# =============================================================================

# Coralogix (or your observability platform)
CORALOGIX_ENABLED=false


# =============================================================================
# DOCKER ENTRYPOINT OPTIONS (if running in containers)
# =============================================================================

# Check database connectivity before starting app
CHECK_DB_CONNECTION=true
